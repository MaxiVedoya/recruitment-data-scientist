{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import all required libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score as R2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Data Preparation</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLAlchemy connectable\n",
    "cnx = create_engine('sqlite:///techtest.db').connect()\n",
    "  \n",
    "# table named 'contacts' will be returned as a dataframe.\n",
    "ad_performance = pd.read_sql_table('ad_performance', cnx)\n",
    "tag = pd.read_sql_table('tag', cnx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag=tag[tag.Confidence>0.9]\n",
    "def timeExtension(end,start):\n",
    "    end=pd.Timestamp(end)\n",
    "    start=pd.Timestamp(start)\n",
    "    diff=end-start\n",
    "    return diff.seconds\n",
    "tag['Exposition']=tag.apply(lambda x: timeExtension(x['End_timestamp'],x['Start_timestamp']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orignalData=pd.merge(\n",
    "                tag,\n",
    "                ad_performance,\n",
    "                how=\"left\",\n",
    "                on=['Ad_id','Asset_id'],\n",
    "                suffixes=(\"_tag\", \"_perf\"),\n",
    "                copy=True,\n",
    "                indicator=False,\n",
    "                validate=None)\n",
    "orignalData.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Prediction</center></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeek(date):\n",
    "    return str(date.week) \n",
    "orignalData['Week']=orignalData.apply(lambda x:getWeek(x['Date_captured']),axis=1)\n",
    "\n",
    "\n",
    "def getFrecuency(Asset_type,Exposition):\n",
    "        if Asset_type=='video' and Exposition>0:\n",
    "            return Exposition\n",
    "        else:\n",
    "            return 1\n",
    "orignalData['Frecuency']=orignalData.apply(lambda x: getFrecuency(x['Asset_type'],x['Exposition']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking into account the main goals of this excercise, I will mainly leverage Tag_name and Tag_type to build the model, following my main points on the remaining predictors\n",
    "\n",
    "* Ad_id: not useful information, it is the id of each element in the tables\n",
    "* Asset_id: this something important if we were to measure performance of each asset, however, here we are trying to explain performance of elements present across all assets. An alternative approach would be to use this as a predictor to understand which asset perform better for each performance metric\n",
    "\n",
    "* Confidence: only used to filter out elements with confidence below the indicated threshold 0.9\n",
    "\n",
    "* Date_captured: there is definitely relevant information here, different dates might play a massive role on cpc or ctr and vvr, this could be used to understand what time is better to display certain elements within our assets. However, for the scope of this analysis I will exclude this categorical variable from the model. This decision is  based on  the fact that the product we are trying to sell (mayonnaise) has no strong seasonality and therefore changes in CPC/CTR across time should not be attribute to changes in demand. For the scope of the available data, changes in performance across time should be related to the use of certain assets (that work better) during that time. Under these assumptions time is strongly correlated to tag_name and tag_type and should not be used\n",
    "\n",
    "* Market: in more detailed analysis this could be used to understand how each element of different assets perform in different regions, for the scope of this analysis I will focus on understand this concept at a global level\n",
    "\n",
    "* Start_timestamp- End_timestamp : only useful on videos as an indirect measure of exposition time, used to compute frequency of usage and not as an independent predictor\n",
    "* Start_frame-End_frame : only useful on videos as an indirect measure of exposition time (noticed that we could use this metric in combination with the previous one to approximate FPS, a quality measure of our asset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "orignalData['Tag_type_Tag_name']=orignalData['Tag_type']+'|'+orignalData['Tag_name']\n",
    "categorical_predictors=['Tag_type_Tag_name']\n",
    "\n",
    "dummies=list()\n",
    "for predictor in categorical_predictors:\n",
    "    dummies.append(pd.get_dummies(orignalData[predictor]))\n",
    "dummies=pd.concat(dummies,axis=1)\n",
    "data=pd.concat([orignalData.drop(columns=categorical_predictors),dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notUsefulPredictors=['Ad_id', 'Asset_id', 'Tag_name', 'Tag_type', 'Confidence','Asset_type',\n",
    "                    'Start_timestamp', 'End_timestamp', 'Start_frame', 'End_frame',\n",
    "                    'Market', 'Date_captured', 'Creative_link','Week','Exposition','Frecuency',\n",
    "                    'CTR', 'CPC', 'VVR']\n",
    "\n",
    "# usefulPrediction-->'Tag_type_Tag_name'\n",
    "\n",
    "varColums=[c for c in data.columns if c not in notUsefulPredictors]\n",
    "\n",
    "# varColums\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative Importance\n",
    "* Using CPC as independet variable determine the most relevant features using a non parametric method , in this case it would be GBM\n",
    "* Using CTR as independet variable determine the most relevant features using a non parametric method , in this case it would be GBM\n",
    "\n",
    "* Leverage these predefined relevant features as the main predictors for a linear model \n",
    "* Take linear model coefficints from these elements to understand how these features are influecing each performance metric \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runRelativeImportance(indpendentVariable,modelreRun,NetreRun,importanceFilter=0.8):\n",
    "    X=data.loc[:,varColums]\n",
    "    y=data.loc[:,indpendentVariable]\n",
    "\n",
    "    X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n",
    "    def trainModel(learning_rate,n_estimators):\n",
    "        gbr=GradientBoostingRegressor(learning_rate=learning_rate,\n",
    "                                    n_estimators=n_estimators)\n",
    "        gbr.fit(X_train,y_train)\n",
    "        y_train_predict=gbr.predict(X_train)\n",
    "        rsme_train=MSE(y_train,y_train_predict)**0.5\n",
    "        y_valid_predict=gbr.predict(X_valid)\n",
    "        rsme_valid=MSE(y_valid,y_valid_predict)**0.5\n",
    "        print(f'{learning_rate} {n_estimators} {rsme_train} {rsme_valid}')\n",
    "        return rsme_train,rsme_valid\n",
    "\n",
    "    ############ Determine best parametrs #####################\n",
    "\n",
    "    if NetreRun:\n",
    "        nitSize=10\n",
    "        parameterNet=pd.DataFrame(columns=['learning_rate','n_estimators','rsme_train','rsme_valid'], index=range(nitSize))\n",
    "        parameterNet['learning_rate']=[0.51-0.05*i for i in range(nitSize)]\n",
    "        parameterNet['n_estimators']=[100+30*i for i in range(nitSize)]\n",
    "        rsme=parameterNet.apply(lambda x:trainModel(x['learning_rate'],x['n_estimators']),axis=1)\n",
    "        parameterNet['rsme_train']=[rsme[row][0] for row in rsme.index]\n",
    "        parameterNet['rsme_valid']=[rsme[row][1] for row in rsme.index]\n",
    "        with open(f'parameterNet{indpendentVariable}.pkl', 'wb') as file:\n",
    "            pickle.dump(parameterNet, file)\n",
    "    else:\n",
    "        with open(f'parameterNet{indpendentVariable}.pkl', 'rb') as file:\n",
    "            parameterNet = pickle.load(file)\n",
    "\n",
    "    if modelreRun:\n",
    "        bestParameter=parameterNet[parameterNet.rsme_valid==parameterNet.rsme_valid.min()].reset_index()\n",
    "        ############ Train the model #####################\n",
    "        gbr=GradientBoostingRegressor(learning_rate=bestParameter.learning_rate.loc[0],\n",
    "                                    n_estimators=bestParameter.n_estimators.loc[0],\n",
    "                                    verbose=1\n",
    "                                    )\n",
    "        \n",
    "        def importantFeatures(model,importanceFilter):\n",
    "            ################### Determine importance of each feature ###########################\n",
    "            relativeImportance=pd.DataFrame(columns=['feature','importance'],index=range(len(model.feature_names_in_)))\n",
    "            relativeImportance['feature']=model.feature_names_in_\n",
    "            relativeImportance['importance']=model.feature_importances_\n",
    "            relativeImportance=relativeImportance.sort_values(by='importance',ascending=False).reset_index()\n",
    "            relativeImportance.drop(columns=['index'],inplace=True)\n",
    "            relativeImportance['CumSum']=relativeImportance.importance.cumsum()\n",
    "            #taking the most important features to reduce model complexity\n",
    "            importantFeatures=relativeImportance[relativeImportance.CumSum<=importanceFilter]\n",
    "            return importantFeatures\n",
    "\n",
    "        # gbr.fit(X_train,y_train)\n",
    "        # importantFeatures=importantFeatures(gbr,importanceFilter)\n",
    "\n",
    "                \n",
    "        #retrain the whole model\n",
    "        gbr.fit(X,y)\n",
    "        importantFeatures=importantFeatures(gbr,importanceFilter)\n",
    "\n",
    "        #train model only using important features\n",
    "        gbr.fit(X_train[importantFeatures.feature],y_train)\n",
    "        y_predict=gbr.predict(X_valid[importantFeatures.feature])\n",
    "        r2_gbm=R2(y_valid,y_predict)\n",
    "        print(f\"{indpendentVariable} GBM r2 {r2_gbm}\")\n",
    "       \n",
    "        \n",
    "        with open(f'gbr{indpendentVariable}.pkl', 'wb') as file:\n",
    "            pickle.dump(gbr, file)\n",
    "        with open(f'r2_gbm{indpendentVariable}.pkl', 'wb') as file:\n",
    "            pickle.dump(r2_gbm, file)\n",
    "        with open(f'importantFeatures{indpendentVariable}.pkl', 'wb') as file:\n",
    "            pickle.dump(importantFeatures, file)\n",
    "    else:\n",
    "        with open(f'gbr{indpendentVariable}.pkl', 'rb') as file:\n",
    "            gbr = pickle.load(file)\n",
    "        with open(f'r2_gbm{indpendentVariable}.pkl', 'rb') as file:\n",
    "            r2_gbm = pickle.load(file)\n",
    "        with open(f'importantFeatures{indpendentVariable}.pkl', 'rb') as file:\n",
    "            importantFeatures = pickle.load(file)\n",
    "        \n",
    "        print(f\"{indpendentVariable} GBM r2 {r2_gbm}\")\n",
    "\n",
    "    model_train =  linear_model.LinearRegression(normalize=True)\n",
    "    model_train.fit(X_train[importantFeatures.feature],y_train)\n",
    "    y_predict=model_train.predict(X_valid[importantFeatures.feature])\n",
    "\n",
    "    print(f\"{indpendentVariable} MLR r2 {R2(y_valid,y_predict)}\")\n",
    "\n",
    "    model_final =  linear_model.LinearRegression(normalize=True)\n",
    "    model_final.fit(X[importantFeatures.feature],y)\n",
    "\n",
    "    return model_final,importantFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPC GBM r2 0.04546807371229611\n",
      "CPC MLR r2 0.04972193179901718\n",
      "CTR GBM r2 0.013501891466862537\n",
      "CTR MLR r2 0.014650273482348708\n"
     ]
    }
   ],
   "source": [
    "#save relative importance\n",
    "model_CPC,importantFeatures_CPC=runRelativeImportance('CPC',NetreRun=False,modelreRun=False)\n",
    "model_CTR,importantFeatures_CTR=runRelativeImportance('CTR',NetreRun=False,modelreRun=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In general models capacity to predict performance in both metric is weak, GMB is better than liner regression but in both cases the percentage of variability explained by the model is low \n",
    "* With this caviat, we can plot the results and get some insights that should be directionally correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "importantFeatures_CPC.to_excel('Results_Importance_CPC.xlsx',index=False)\n",
    "importantFeatures_CTR.to_excel('Results_Importance_CTR.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=model_CPC.coef_\n",
    "tag_type=[element.split('|')[0] for element in model_CPC.feature_names_in_]\n",
    "tag_name=[element.split('|')[1] for element in model_CPC.feature_names_in_]\n",
    "\n",
    "results=pd.DataFrame(columns=['Tag_type','Tag_name','Value'],index=range(len(values)))\n",
    "\n",
    "results['Tag_type']=tag_type\n",
    "results['Tag_name']=tag_name\n",
    "results['Value']=values\n",
    "# results['Metric']='CPC'\n",
    "cpc=results.sort_values('Value',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=model_CTR.coef_\n",
    "tag_type=[element.split('|')[0] for element in model_CTR.feature_names_in_]\n",
    "tag_name=[element.split('|')[1] for element in model_CTR.feature_names_in_]\n",
    "\n",
    "results=pd.DataFrame(columns=['Tag_type','Tag_name','Value'],index=range(len(values)))\n",
    "\n",
    "results['Tag_type']=tag_type\n",
    "results['Tag_name']=tag_name\n",
    "results['Value']=values\n",
    "# results['Metric']='CTR'\n",
    "ctr=results.sort_values('Value',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Determine frecuency for relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take creative element important for both metrics\n",
    "result=pd.merge(cpc,\n",
    "                ctr,\n",
    "                how=\"inner\",\n",
    "                on=['Tag_type','Tag_name'],\n",
    "                suffixes=(\"_cpc\", \"_ctr\"),\n",
    "                copy=True,\n",
    "                indicator=False,\n",
    "                validate=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add asset type and exposition time \n",
    "\n",
    "aux=orignalData.groupby(['Tag_type','Tag_name'])['Frecuency'].sum().reset_index()\n",
    "result=pd.merge(result,\n",
    "                aux,\n",
    "                how=\"left\",\n",
    "                on=['Tag_type','Tag_name'],\n",
    "                suffixes=(\"_r\", \"_r2\"),\n",
    "                copy=True,\n",
    "                indicator=False,\n",
    "                validate=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize results \n",
    "result['Value_cpc']=MinMaxScaler((-1,1)).fit_transform(np.array(result['Value_cpc']).reshape(-1,1))\n",
    "result['Value_ctr']=MinMaxScaler((-1,1)).fit_transform(np.array(result['Value_ctr']).reshape(-1,1))\n",
    "result['Frecuency']=MinMaxScaler((0,1)).fit_transform(np.array(result['Frecuency']).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel('results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6f6c3541abca5724a07bbdbaae21b5643d2cab24b98a310e9f2bde414f3dd03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
